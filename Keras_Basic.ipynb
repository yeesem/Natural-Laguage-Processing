{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNuOVoxkxay0hIb0QNhcY/o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yeesem/Natural-Laguage-Processing/blob/main/Keras_Basic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "C7BKBqeXieb8"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris"
      ],
      "metadata": {
        "id": "veVfq5-6irXb"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iris = load_iris()"
      ],
      "metadata": {
        "id": "EkM_08Rsit9t"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(iris)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2YPcj2jiwjh",
        "outputId": "0499925e-ca67-4b3f-86d0-cd55329827ad"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sklearn.utils._bunch.Bunch"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Print the description of the dataset\n",
        "print(iris.DESCR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_gBTDIznizra",
        "outputId": "16d4cc9e-f774-46ee-ab6b-840896d8b442"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".. _iris_dataset:\n",
            "\n",
            "Iris plants dataset\n",
            "--------------------\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            "    :Number of Instances: 150 (50 in each of three classes)\n",
            "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
            "    :Attribute Information:\n",
            "        - sepal length in cm\n",
            "        - sepal width in cm\n",
            "        - petal length in cm\n",
            "        - petal width in cm\n",
            "        - class:\n",
            "                - Iris-Setosa\n",
            "                - Iris-Versicolour\n",
            "                - Iris-Virginica\n",
            "                \n",
            "    :Summary Statistics:\n",
            "\n",
            "    ============== ==== ==== ======= ===== ====================\n",
            "                    Min  Max   Mean    SD   Class Correlation\n",
            "    ============== ==== ==== ======= ===== ====================\n",
            "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
            "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
            "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
            "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
            "    ============== ==== ==== ======= ===== ====================\n",
            "\n",
            "    :Missing Attribute Values: None\n",
            "    :Class Distribution: 33.3% for each of 3 classes.\n",
            "    :Creator: R.A. Fisher\n",
            "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
            "    :Date: July, 1988\n",
            "\n",
            "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
            "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
            "Machine Learning Repository, which has two wrong data points.\n",
            "\n",
            "This is perhaps the best known database to be found in the\n",
            "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
            "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
            "data set contains 3 classes of 50 instances each, where each class refers to a\n",
            "type of iris plant.  One class is linearly separable from the other 2; the\n",
            "latter are NOT linearly separable from each other.\n",
            "\n",
            ".. topic:: References\n",
            "\n",
            "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
            "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
            "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
            "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
            "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
            "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
            "     Structure and Classification Rule for Recognition in Partially Exposed\n",
            "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
            "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
            "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
            "     on Information Theory, May 1972, 431-433.\n",
            "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
            "     conceptual clustering system finds 3 classes in the data.\n",
            "   - Many, many more ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = iris.data"
      ],
      "metadata": {
        "id": "xz5eWsRsi7G_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = iris.target"
      ],
      "metadata": {
        "id": "7NfjhEv0jXan"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "__h3D2M_jXso"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = to_categorical(y)"
      ],
      "metadata": {
        "id": "N0LMxuGyj8aG"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-jkVmU4j_CG",
        "outputId": "b0621284-0d04-4bbb-a998-cab57f3fb9c5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Class 1 -> [1,0,0]\n",
        "#Class 2 -> [0,1,0]\n",
        "#Class 3 -> [0,0,1]\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqus7HsukBLy",
        "outputId": "03b15370-bcc2-45a0-c575-256a1e24f60f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "rhNlBfMjkBm0"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "XTrain,XTest,YTrain,YTest = train_test_split(X,y,test_size = 0.33,random_state = 42)"
      ],
      "metadata": {
        "id": "6aWZG3XokRGM"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "metadata": {
        "id": "0oQgNBeukfNV"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler_object = MinMaxScaler()"
      ],
      "metadata": {
        "id": "sAOFmFNekzhL"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler_object.fit(XTrain)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "qpBzLzc2mmiR",
        "outputId": "3d8f79a0-11ad-40b6-bf5a-548ee34996c4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MinMaxScaler()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MinMaxScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaled_XTrain = scaler_object.transform(XTrain)"
      ],
      "metadata": {
        "id": "TCcQW92KmqJV"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaled_XTest = scaler_object.transform(XTest)"
      ],
      "metadata": {
        "id": "FdpL-wZhmyut"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#All the data is between 0 and 1\n",
        "scaled_XTrain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "byeOw2ArnOF2",
        "outputId": "29adcfa3-bd30-463e-d4d9-0e76bc0b79a6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.41176471, 0.40909091, 0.55357143, 0.5       ],\n",
              "       [0.97058824, 0.45454545, 0.98214286, 0.83333333],\n",
              "       [0.38235294, 0.45454545, 0.60714286, 0.58333333],\n",
              "       [0.23529412, 0.68181818, 0.05357143, 0.04166667],\n",
              "       [1.        , 0.36363636, 1.        , 0.79166667],\n",
              "       [0.44117647, 0.31818182, 0.53571429, 0.375     ],\n",
              "       [0.26470588, 0.63636364, 0.05357143, 0.04166667],\n",
              "       [0.20588235, 0.68181818, 0.03571429, 0.08333333],\n",
              "       [0.23529412, 0.81818182, 0.14285714, 0.125     ],\n",
              "       [0.20588235, 0.        , 0.42857143, 0.375     ],\n",
              "       [0.58823529, 0.31818182, 0.67857143, 0.70833333],\n",
              "       [0.14705882, 0.63636364, 0.14285714, 0.04166667],\n",
              "       [0.20588235, 0.45454545, 0.08928571, 0.04166667],\n",
              "       [0.23529412, 0.59090909, 0.10714286, 0.16666667],\n",
              "       [0.38235294, 0.31818182, 0.55357143, 0.5       ],\n",
              "       [0.23529412, 0.63636364, 0.07142857, 0.04166667],\n",
              "       [0.41176471, 0.45454545, 0.55357143, 0.45833333],\n",
              "       [1.        , 0.81818182, 1.        , 0.875     ],\n",
              "       [0.08823529, 0.54545455, 0.05357143, 0.04166667],\n",
              "       [0.55882353, 0.40909091, 0.57142857, 0.5       ],\n",
              "       [0.41176471, 0.22727273, 0.69642857, 0.79166667],\n",
              "       [0.35294118, 1.        , 0.05357143, 0.04166667],\n",
              "       [0.5       , 0.45454545, 0.66071429, 0.70833333],\n",
              "       [0.44117647, 0.31818182, 0.71428571, 0.75      ],\n",
              "       [0.5       , 0.09090909, 0.51785714, 0.375     ],\n",
              "       [0.32352941, 0.45454545, 0.60714286, 0.58333333],\n",
              "       [0.55882353, 0.63636364, 0.76785714, 0.91666667],\n",
              "       [0.35294118, 0.13636364, 0.51785714, 0.5       ],\n",
              "       [0.32352941, 0.86363636, 0.10714286, 0.125     ],\n",
              "       [0.20588235, 0.13636364, 0.39285714, 0.375     ],\n",
              "       [0.61764706, 0.31818182, 0.75      , 0.75      ],\n",
              "       [0.20588235, 0.59090909, 0.05357143, 0.04166667],\n",
              "       [0.20588235, 0.54545455, 0.01785714, 0.04166667],\n",
              "       [0.35294118, 0.18181818, 0.48214286, 0.41666667],\n",
              "       [0.70588235, 0.45454545, 0.69642857, 0.66666667],\n",
              "       [0.17647059, 0.5       , 0.07142857, 0.04166667],\n",
              "       [0.44117647, 0.36363636, 0.71428571, 0.95833333],\n",
              "       [0.20588235, 0.63636364, 0.07142857, 0.04166667],\n",
              "       [0.20588235, 0.68181818, 0.08928571, 0.20833333],\n",
              "       [0.47058824, 0.54545455, 0.66071429, 0.70833333],\n",
              "       [0.23529412, 0.22727273, 0.33928571, 0.41666667],\n",
              "       [0.76470588, 0.54545455, 0.82142857, 0.91666667],\n",
              "       [0.5       , 0.31818182, 0.71428571, 0.625     ],\n",
              "       [0.52941176, 0.27272727, 0.80357143, 0.54166667],\n",
              "       [1.        , 0.45454545, 0.89285714, 0.91666667],\n",
              "       [0.35294118, 0.22727273, 0.51785714, 0.5       ],\n",
              "       [0.02941176, 0.40909091, 0.05357143, 0.04166667],\n",
              "       [0.        , 0.45454545, 0.        , 0.        ],\n",
              "       [0.5       , 0.09090909, 0.69642857, 0.58333333],\n",
              "       [0.85294118, 0.54545455, 0.875     , 0.70833333],\n",
              "       [0.08823529, 0.5       , 0.07142857, 0.04166667],\n",
              "       [0.23529412, 0.68181818, 0.05357143, 0.08333333],\n",
              "       [0.02941176, 0.45454545, 0.03571429, 0.04166667],\n",
              "       [0.58823529, 0.22727273, 0.67857143, 0.58333333],\n",
              "       [0.58823529, 0.63636364, 0.80357143, 0.95833333],\n",
              "       [0.08823529, 0.63636364, 0.05357143, 0.08333333],\n",
              "       [0.73529412, 0.45454545, 0.78571429, 0.83333333],\n",
              "       [0.58823529, 0.59090909, 0.875     , 1.        ],\n",
              "       [0.11764706, 0.54545455, 0.03571429, 0.04166667],\n",
              "       [0.52941176, 0.40909091, 0.64285714, 0.54166667],\n",
              "       [0.64705882, 0.36363636, 0.625     , 0.58333333],\n",
              "       [0.55882353, 0.36363636, 0.66071429, 0.70833333],\n",
              "       [0.79411765, 0.54545455, 0.64285714, 0.54166667],\n",
              "       [0.61764706, 0.54545455, 0.75      , 0.91666667],\n",
              "       [0.23529412, 0.81818182, 0.08928571, 0.04166667],\n",
              "       [0.76470588, 0.5       , 0.76785714, 0.83333333],\n",
              "       [0.47058824, 0.45454545, 0.55357143, 0.58333333],\n",
              "       [0.64705882, 0.45454545, 0.73214286, 0.79166667],\n",
              "       [0.41176471, 0.27272727, 0.42857143, 0.375     ],\n",
              "       [0.26470588, 0.31818182, 0.5       , 0.54166667],\n",
              "       [0.52941176, 0.45454545, 0.625     , 0.54166667],\n",
              "       [0.05882353, 0.13636364, 0.03571429, 0.08333333],\n",
              "       [0.67647059, 0.40909091, 0.625     , 0.5       ],\n",
              "       [0.35294118, 0.27272727, 0.58928571, 0.45833333],\n",
              "       [0.29411765, 0.77272727, 0.07142857, 0.04166667],\n",
              "       [0.38235294, 0.45454545, 0.53571429, 0.5       ],\n",
              "       [0.88235294, 0.40909091, 0.92857143, 0.70833333],\n",
              "       [0.70588235, 0.59090909, 0.82142857, 0.83333333],\n",
              "       [0.23529412, 0.77272727, 0.07142857, 0.125     ],\n",
              "       [0.17647059, 0.18181818, 0.39285714, 0.375     ],\n",
              "       [0.70588235, 0.59090909, 0.82142857, 1.        ],\n",
              "       [0.85294118, 0.45454545, 0.83928571, 0.625     ],\n",
              "       [0.17647059, 0.72727273, 0.05357143, 0.        ],\n",
              "       [0.70588235, 0.5       , 0.80357143, 0.95833333],\n",
              "       [0.17647059, 0.45454545, 0.05357143, 0.04166667],\n",
              "       [0.76470588, 0.5       , 0.67857143, 0.58333333],\n",
              "       [0.91176471, 0.36363636, 0.89285714, 0.75      ],\n",
              "       [0.58823529, 0.40909091, 0.80357143, 0.70833333],\n",
              "       [0.41176471, 0.36363636, 0.53571429, 0.5       ],\n",
              "       [0.64705882, 0.45454545, 0.78571429, 0.70833333],\n",
              "       [0.58823529, 0.13636364, 0.58928571, 0.5       ],\n",
              "       [0.61764706, 0.40909091, 0.57142857, 0.5       ],\n",
              "       [0.38235294, 0.36363636, 0.67857143, 0.79166667],\n",
              "       [0.47058824, 0.45454545, 0.71428571, 0.70833333],\n",
              "       [0.32352941, 0.63636364, 0.10714286, 0.04166667],\n",
              "       [0.52941176, 0.36363636, 0.51785714, 0.5       ],\n",
              "       [0.17647059, 0.22727273, 0.60714286, 0.66666667],\n",
              "       [0.44117647, 0.90909091, 0.01785714, 0.04166667],\n",
              "       [0.44117647, 0.27272727, 0.51785714, 0.45833333],\n",
              "       [0.82352941, 0.45454545, 0.85714286, 0.83333333]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ],
      "metadata": {
        "id": "swLGYiVDnRLm"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(8,input_dim = 4,activation = 'relu'))\n",
        "model.add(Dense(8,input_dim = 4,activation = 'relu'))\n",
        "model.add(Dense(3,activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer = 'adam',\n",
        "              metrics = ['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "q3Lmwj5Nnbdd"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.keras.utils.plot_model(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "u43weGiMrlqH",
        "outputId": "ebc1c327-07e3-4f2b-d482-4ebc9bb8adfe"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6ZNBvstoTko",
        "outputId": "b07b7de3-783f-4c2e-dcf1-c41d33da9195"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 8)                 40        \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 8)                 72        \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 3)                 27        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 139 (556.00 Byte)\n",
            "Trainable params: 139 (556.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r = model.fit(\n",
        "    scaled_XTrain,\n",
        "    YTrain,\n",
        "    epochs = 150,\n",
        "    verbose = 2,\n",
        "    validation_data = (scaled_XTest,YTest)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4pyLx4OKoV5C",
        "outputId": "423b2c5d-68b7-4030-fd7b-29397f9627ca"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "4/4 - 5s - loss: 1.1984 - accuracy: 0.3400 - val_loss: 1.1905 - val_accuracy: 0.3000 - 5s/epoch - 1s/step\n",
            "Epoch 2/150\n",
            "4/4 - 0s - loss: 1.1823 - accuracy: 0.3400 - val_loss: 1.1779 - val_accuracy: 0.3000 - 63ms/epoch - 16ms/step\n",
            "Epoch 3/150\n",
            "4/4 - 0s - loss: 1.1707 - accuracy: 0.3400 - val_loss: 1.1672 - val_accuracy: 0.3000 - 80ms/epoch - 20ms/step\n",
            "Epoch 4/150\n",
            "4/4 - 0s - loss: 1.1597 - accuracy: 0.3400 - val_loss: 1.1569 - val_accuracy: 0.3000 - 113ms/epoch - 28ms/step\n",
            "Epoch 5/150\n",
            "4/4 - 0s - loss: 1.1485 - accuracy: 0.3400 - val_loss: 1.1479 - val_accuracy: 0.3000 - 84ms/epoch - 21ms/step\n",
            "Epoch 6/150\n",
            "4/4 - 0s - loss: 1.1394 - accuracy: 0.3400 - val_loss: 1.1386 - val_accuracy: 0.3000 - 74ms/epoch - 19ms/step\n",
            "Epoch 7/150\n",
            "4/4 - 0s - loss: 1.1310 - accuracy: 0.3400 - val_loss: 1.1295 - val_accuracy: 0.3000 - 74ms/epoch - 19ms/step\n",
            "Epoch 8/150\n",
            "4/4 - 0s - loss: 1.1231 - accuracy: 0.3400 - val_loss: 1.1215 - val_accuracy: 0.3000 - 78ms/epoch - 20ms/step\n",
            "Epoch 9/150\n",
            "4/4 - 0s - loss: 1.1152 - accuracy: 0.3400 - val_loss: 1.1141 - val_accuracy: 0.3000 - 74ms/epoch - 18ms/step\n",
            "Epoch 10/150\n",
            "4/4 - 0s - loss: 1.1078 - accuracy: 0.3400 - val_loss: 1.1074 - val_accuracy: 0.3000 - 75ms/epoch - 19ms/step\n",
            "Epoch 11/150\n",
            "4/4 - 0s - loss: 1.1000 - accuracy: 0.3400 - val_loss: 1.1009 - val_accuracy: 0.3000 - 138ms/epoch - 34ms/step\n",
            "Epoch 12/150\n",
            "4/4 - 0s - loss: 1.0926 - accuracy: 0.3400 - val_loss: 1.0942 - val_accuracy: 0.3000 - 103ms/epoch - 26ms/step\n",
            "Epoch 13/150\n",
            "4/4 - 0s - loss: 1.0853 - accuracy: 0.3400 - val_loss: 1.0880 - val_accuracy: 0.3000 - 124ms/epoch - 31ms/step\n",
            "Epoch 14/150\n",
            "4/4 - 0s - loss: 1.0787 - accuracy: 0.3400 - val_loss: 1.0816 - val_accuracy: 0.3000 - 129ms/epoch - 32ms/step\n",
            "Epoch 15/150\n",
            "4/4 - 0s - loss: 1.0731 - accuracy: 0.3400 - val_loss: 1.0761 - val_accuracy: 0.3000 - 131ms/epoch - 33ms/step\n",
            "Epoch 16/150\n",
            "4/4 - 0s - loss: 1.0670 - accuracy: 0.3400 - val_loss: 1.0714 - val_accuracy: 0.3000 - 115ms/epoch - 29ms/step\n",
            "Epoch 17/150\n",
            "4/4 - 0s - loss: 1.0615 - accuracy: 0.3400 - val_loss: 1.0662 - val_accuracy: 0.3000 - 110ms/epoch - 28ms/step\n",
            "Epoch 18/150\n",
            "4/4 - 0s - loss: 1.0560 - accuracy: 0.3300 - val_loss: 1.0606 - val_accuracy: 0.3000 - 215ms/epoch - 54ms/step\n",
            "Epoch 19/150\n",
            "4/4 - 0s - loss: 1.0506 - accuracy: 0.3300 - val_loss: 1.0549 - val_accuracy: 0.2800 - 102ms/epoch - 25ms/step\n",
            "Epoch 20/150\n",
            "4/4 - 0s - loss: 1.0453 - accuracy: 0.3100 - val_loss: 1.0491 - val_accuracy: 0.2800 - 147ms/epoch - 37ms/step\n",
            "Epoch 21/150\n",
            "4/4 - 0s - loss: 1.0395 - accuracy: 0.3100 - val_loss: 1.0432 - val_accuracy: 0.2400 - 181ms/epoch - 45ms/step\n",
            "Epoch 22/150\n",
            "4/4 - 0s - loss: 1.0338 - accuracy: 0.2500 - val_loss: 1.0368 - val_accuracy: 0.2000 - 125ms/epoch - 31ms/step\n",
            "Epoch 23/150\n",
            "4/4 - 0s - loss: 1.0287 - accuracy: 0.2300 - val_loss: 1.0309 - val_accuracy: 0.1800 - 132ms/epoch - 33ms/step\n",
            "Epoch 24/150\n",
            "4/4 - 0s - loss: 1.0238 - accuracy: 0.1700 - val_loss: 1.0255 - val_accuracy: 0.1800 - 131ms/epoch - 33ms/step\n",
            "Epoch 25/150\n",
            "4/4 - 0s - loss: 1.0182 - accuracy: 0.1400 - val_loss: 1.0201 - val_accuracy: 0.1800 - 102ms/epoch - 25ms/step\n",
            "Epoch 26/150\n",
            "4/4 - 0s - loss: 1.0132 - accuracy: 0.2200 - val_loss: 1.0146 - val_accuracy: 0.2400 - 196ms/epoch - 49ms/step\n",
            "Epoch 27/150\n",
            "4/4 - 0s - loss: 1.0079 - accuracy: 0.2700 - val_loss: 1.0092 - val_accuracy: 0.3200 - 140ms/epoch - 35ms/step\n",
            "Epoch 28/150\n",
            "4/4 - 0s - loss: 1.0024 - accuracy: 0.3300 - val_loss: 1.0034 - val_accuracy: 0.3600 - 190ms/epoch - 48ms/step\n",
            "Epoch 29/150\n",
            "4/4 - 0s - loss: 0.9977 - accuracy: 0.4100 - val_loss: 0.9977 - val_accuracy: 0.3800 - 104ms/epoch - 26ms/step\n",
            "Epoch 30/150\n",
            "4/4 - 0s - loss: 0.9925 - accuracy: 0.4100 - val_loss: 0.9925 - val_accuracy: 0.3800 - 148ms/epoch - 37ms/step\n",
            "Epoch 31/150\n",
            "4/4 - 0s - loss: 0.9870 - accuracy: 0.4300 - val_loss: 0.9871 - val_accuracy: 0.4000 - 119ms/epoch - 30ms/step\n",
            "Epoch 32/150\n",
            "4/4 - 0s - loss: 0.9820 - accuracy: 0.4500 - val_loss: 0.9814 - val_accuracy: 0.4200 - 105ms/epoch - 26ms/step\n",
            "Epoch 33/150\n",
            "4/4 - 0s - loss: 0.9765 - accuracy: 0.4800 - val_loss: 0.9759 - val_accuracy: 0.4800 - 153ms/epoch - 38ms/step\n",
            "Epoch 34/150\n",
            "4/4 - 0s - loss: 0.9711 - accuracy: 0.5200 - val_loss: 0.9699 - val_accuracy: 0.5200 - 128ms/epoch - 32ms/step\n",
            "Epoch 35/150\n",
            "4/4 - 0s - loss: 0.9654 - accuracy: 0.5400 - val_loss: 0.9636 - val_accuracy: 0.6200 - 150ms/epoch - 38ms/step\n",
            "Epoch 36/150\n",
            "4/4 - 0s - loss: 0.9596 - accuracy: 0.5900 - val_loss: 0.9573 - val_accuracy: 0.6600 - 112ms/epoch - 28ms/step\n",
            "Epoch 37/150\n",
            "4/4 - 0s - loss: 0.9539 - accuracy: 0.6100 - val_loss: 0.9508 - val_accuracy: 0.6600 - 99ms/epoch - 25ms/step\n",
            "Epoch 38/150\n",
            "4/4 - 0s - loss: 0.9477 - accuracy: 0.6300 - val_loss: 0.9435 - val_accuracy: 0.6800 - 72ms/epoch - 18ms/step\n",
            "Epoch 39/150\n",
            "4/4 - 0s - loss: 0.9422 - accuracy: 0.6400 - val_loss: 0.9362 - val_accuracy: 0.7000 - 203ms/epoch - 51ms/step\n",
            "Epoch 40/150\n",
            "4/4 - 0s - loss: 0.9358 - accuracy: 0.6500 - val_loss: 0.9288 - val_accuracy: 0.7000 - 137ms/epoch - 34ms/step\n",
            "Epoch 41/150\n",
            "4/4 - 0s - loss: 0.9297 - accuracy: 0.6500 - val_loss: 0.9215 - val_accuracy: 0.7000 - 55ms/epoch - 14ms/step\n",
            "Epoch 42/150\n",
            "4/4 - 0s - loss: 0.9237 - accuracy: 0.6500 - val_loss: 0.9144 - val_accuracy: 0.7000 - 77ms/epoch - 19ms/step\n",
            "Epoch 43/150\n",
            "4/4 - 0s - loss: 0.9171 - accuracy: 0.6500 - val_loss: 0.9074 - val_accuracy: 0.7000 - 130ms/epoch - 33ms/step\n",
            "Epoch 44/150\n",
            "4/4 - 0s - loss: 0.9104 - accuracy: 0.6500 - val_loss: 0.8998 - val_accuracy: 0.7000 - 112ms/epoch - 28ms/step\n",
            "Epoch 45/150\n",
            "4/4 - 0s - loss: 0.9032 - accuracy: 0.6500 - val_loss: 0.8923 - val_accuracy: 0.7000 - 85ms/epoch - 21ms/step\n",
            "Epoch 46/150\n",
            "4/4 - 0s - loss: 0.8961 - accuracy: 0.6500 - val_loss: 0.8847 - val_accuracy: 0.7000 - 73ms/epoch - 18ms/step\n",
            "Epoch 47/150\n",
            "4/4 - 0s - loss: 0.8891 - accuracy: 0.6500 - val_loss: 0.8769 - val_accuracy: 0.7000 - 72ms/epoch - 18ms/step\n",
            "Epoch 48/150\n",
            "4/4 - 0s - loss: 0.8814 - accuracy: 0.6500 - val_loss: 0.8679 - val_accuracy: 0.7000 - 70ms/epoch - 17ms/step\n",
            "Epoch 49/150\n",
            "4/4 - 0s - loss: 0.8732 - accuracy: 0.6500 - val_loss: 0.8583 - val_accuracy: 0.7000 - 67ms/epoch - 17ms/step\n",
            "Epoch 50/150\n",
            "4/4 - 0s - loss: 0.8643 - accuracy: 0.6500 - val_loss: 0.8491 - val_accuracy: 0.7000 - 69ms/epoch - 17ms/step\n",
            "Epoch 51/150\n",
            "4/4 - 0s - loss: 0.8556 - accuracy: 0.6500 - val_loss: 0.8396 - val_accuracy: 0.7000 - 85ms/epoch - 21ms/step\n",
            "Epoch 52/150\n",
            "4/4 - 0s - loss: 0.8472 - accuracy: 0.6500 - val_loss: 0.8300 - val_accuracy: 0.7000 - 66ms/epoch - 16ms/step\n",
            "Epoch 53/150\n",
            "4/4 - 0s - loss: 0.8376 - accuracy: 0.6500 - val_loss: 0.8200 - val_accuracy: 0.7000 - 65ms/epoch - 16ms/step\n",
            "Epoch 54/150\n",
            "4/4 - 0s - loss: 0.8286 - accuracy: 0.6500 - val_loss: 0.8093 - val_accuracy: 0.7000 - 72ms/epoch - 18ms/step\n",
            "Epoch 55/150\n",
            "4/4 - 0s - loss: 0.8188 - accuracy: 0.6500 - val_loss: 0.7985 - val_accuracy: 0.7000 - 118ms/epoch - 29ms/step\n",
            "Epoch 56/150\n",
            "4/4 - 0s - loss: 0.8102 - accuracy: 0.6500 - val_loss: 0.7879 - val_accuracy: 0.7000 - 69ms/epoch - 17ms/step\n",
            "Epoch 57/150\n",
            "4/4 - 0s - loss: 0.8004 - accuracy: 0.6500 - val_loss: 0.7779 - val_accuracy: 0.7000 - 106ms/epoch - 27ms/step\n",
            "Epoch 58/150\n",
            "4/4 - 0s - loss: 0.7909 - accuracy: 0.6500 - val_loss: 0.7674 - val_accuracy: 0.7000 - 89ms/epoch - 22ms/step\n",
            "Epoch 59/150\n",
            "4/4 - 0s - loss: 0.7812 - accuracy: 0.6500 - val_loss: 0.7559 - val_accuracy: 0.7000 - 138ms/epoch - 35ms/step\n",
            "Epoch 60/150\n",
            "4/4 - 0s - loss: 0.7722 - accuracy: 0.6500 - val_loss: 0.7444 - val_accuracy: 0.7000 - 133ms/epoch - 33ms/step\n",
            "Epoch 61/150\n",
            "4/4 - 0s - loss: 0.7617 - accuracy: 0.6700 - val_loss: 0.7330 - val_accuracy: 0.7000 - 151ms/epoch - 38ms/step\n",
            "Epoch 62/150\n",
            "4/4 - 0s - loss: 0.7523 - accuracy: 0.6800 - val_loss: 0.7220 - val_accuracy: 0.7000 - 115ms/epoch - 29ms/step\n",
            "Epoch 63/150\n",
            "4/4 - 0s - loss: 0.7434 - accuracy: 0.6800 - val_loss: 0.7110 - val_accuracy: 0.7000 - 185ms/epoch - 46ms/step\n",
            "Epoch 64/150\n",
            "4/4 - 0s - loss: 0.7341 - accuracy: 0.6800 - val_loss: 0.7000 - val_accuracy: 0.7000 - 164ms/epoch - 41ms/step\n",
            "Epoch 65/150\n",
            "4/4 - 0s - loss: 0.7242 - accuracy: 0.6800 - val_loss: 0.6893 - val_accuracy: 0.7000 - 200ms/epoch - 50ms/step\n",
            "Epoch 66/150\n",
            "4/4 - 0s - loss: 0.7156 - accuracy: 0.6800 - val_loss: 0.6786 - val_accuracy: 0.7000 - 120ms/epoch - 30ms/step\n",
            "Epoch 67/150\n",
            "4/4 - 0s - loss: 0.7063 - accuracy: 0.6800 - val_loss: 0.6691 - val_accuracy: 0.7000 - 123ms/epoch - 31ms/step\n",
            "Epoch 68/150\n",
            "4/4 - 0s - loss: 0.6981 - accuracy: 0.6700 - val_loss: 0.6604 - val_accuracy: 0.7000 - 176ms/epoch - 44ms/step\n",
            "Epoch 69/150\n",
            "4/4 - 0s - loss: 0.6900 - accuracy: 0.6700 - val_loss: 0.6518 - val_accuracy: 0.7000 - 192ms/epoch - 48ms/step\n",
            "Epoch 70/150\n",
            "4/4 - 0s - loss: 0.6818 - accuracy: 0.6800 - val_loss: 0.6432 - val_accuracy: 0.7000 - 99ms/epoch - 25ms/step\n",
            "Epoch 71/150\n",
            "4/4 - 0s - loss: 0.6734 - accuracy: 0.6800 - val_loss: 0.6345 - val_accuracy: 0.7000 - 191ms/epoch - 48ms/step\n",
            "Epoch 72/150\n",
            "4/4 - 0s - loss: 0.6654 - accuracy: 0.6800 - val_loss: 0.6261 - val_accuracy: 0.7000 - 110ms/epoch - 27ms/step\n",
            "Epoch 73/150\n",
            "4/4 - 0s - loss: 0.6581 - accuracy: 0.6900 - val_loss: 0.6181 - val_accuracy: 0.7400 - 151ms/epoch - 38ms/step\n",
            "Epoch 74/150\n",
            "4/4 - 0s - loss: 0.6506 - accuracy: 0.7000 - val_loss: 0.6103 - val_accuracy: 0.7400 - 130ms/epoch - 32ms/step\n",
            "Epoch 75/150\n",
            "4/4 - 0s - loss: 0.6441 - accuracy: 0.7200 - val_loss: 0.6028 - val_accuracy: 0.7800 - 227ms/epoch - 57ms/step\n",
            "Epoch 76/150\n",
            "4/4 - 0s - loss: 0.6368 - accuracy: 0.7500 - val_loss: 0.5958 - val_accuracy: 0.7800 - 166ms/epoch - 42ms/step\n",
            "Epoch 77/150\n",
            "4/4 - 0s - loss: 0.6301 - accuracy: 0.7700 - val_loss: 0.5887 - val_accuracy: 0.7800 - 109ms/epoch - 27ms/step\n",
            "Epoch 78/150\n",
            "4/4 - 0s - loss: 0.6235 - accuracy: 0.8000 - val_loss: 0.5811 - val_accuracy: 0.7800 - 149ms/epoch - 37ms/step\n",
            "Epoch 79/150\n",
            "4/4 - 0s - loss: 0.6168 - accuracy: 0.8000 - val_loss: 0.5739 - val_accuracy: 0.7800 - 192ms/epoch - 48ms/step\n",
            "Epoch 80/150\n",
            "4/4 - 0s - loss: 0.6104 - accuracy: 0.8100 - val_loss: 0.5667 - val_accuracy: 0.7800 - 126ms/epoch - 32ms/step\n",
            "Epoch 81/150\n",
            "4/4 - 0s - loss: 0.6039 - accuracy: 0.7600 - val_loss: 0.5599 - val_accuracy: 0.7800 - 86ms/epoch - 22ms/step\n",
            "Epoch 82/150\n",
            "4/4 - 0s - loss: 0.5976 - accuracy: 0.7400 - val_loss: 0.5532 - val_accuracy: 0.7800 - 89ms/epoch - 22ms/step\n",
            "Epoch 83/150\n",
            "4/4 - 0s - loss: 0.5922 - accuracy: 0.7500 - val_loss: 0.5470 - val_accuracy: 0.7800 - 100ms/epoch - 25ms/step\n",
            "Epoch 84/150\n",
            "4/4 - 0s - loss: 0.5859 - accuracy: 0.8000 - val_loss: 0.5409 - val_accuracy: 0.7800 - 77ms/epoch - 19ms/step\n",
            "Epoch 85/150\n",
            "4/4 - 0s - loss: 0.5810 - accuracy: 0.8000 - val_loss: 0.5345 - val_accuracy: 0.7800 - 82ms/epoch - 21ms/step\n",
            "Epoch 86/150\n",
            "4/4 - 0s - loss: 0.5753 - accuracy: 0.8200 - val_loss: 0.5291 - val_accuracy: 0.7800 - 176ms/epoch - 44ms/step\n",
            "Epoch 87/150\n",
            "4/4 - 0s - loss: 0.5700 - accuracy: 0.8500 - val_loss: 0.5238 - val_accuracy: 0.7800 - 161ms/epoch - 40ms/step\n",
            "Epoch 88/150\n",
            "4/4 - 0s - loss: 0.5648 - accuracy: 0.8800 - val_loss: 0.5187 - val_accuracy: 0.8200 - 102ms/epoch - 26ms/step\n",
            "Epoch 89/150\n",
            "4/4 - 0s - loss: 0.5598 - accuracy: 0.8900 - val_loss: 0.5140 - val_accuracy: 0.8200 - 90ms/epoch - 22ms/step\n",
            "Epoch 90/150\n",
            "4/4 - 0s - loss: 0.5553 - accuracy: 0.9000 - val_loss: 0.5091 - val_accuracy: 0.9000 - 88ms/epoch - 22ms/step\n",
            "Epoch 91/150\n",
            "4/4 - 0s - loss: 0.5504 - accuracy: 0.9000 - val_loss: 0.5047 - val_accuracy: 0.9400 - 96ms/epoch - 24ms/step\n",
            "Epoch 92/150\n",
            "4/4 - 0s - loss: 0.5463 - accuracy: 0.9000 - val_loss: 0.4998 - val_accuracy: 0.9400 - 70ms/epoch - 17ms/step\n",
            "Epoch 93/150\n",
            "4/4 - 0s - loss: 0.5412 - accuracy: 0.9000 - val_loss: 0.4945 - val_accuracy: 0.9000 - 78ms/epoch - 20ms/step\n",
            "Epoch 94/150\n",
            "4/4 - 0s - loss: 0.5364 - accuracy: 0.9000 - val_loss: 0.4895 - val_accuracy: 0.9000 - 82ms/epoch - 21ms/step\n",
            "Epoch 95/150\n",
            "4/4 - 0s - loss: 0.5321 - accuracy: 0.9000 - val_loss: 0.4855 - val_accuracy: 0.9400 - 68ms/epoch - 17ms/step\n",
            "Epoch 96/150\n",
            "4/4 - 0s - loss: 0.5277 - accuracy: 0.9000 - val_loss: 0.4808 - val_accuracy: 0.9400 - 63ms/epoch - 16ms/step\n",
            "Epoch 97/150\n",
            "4/4 - 0s - loss: 0.5232 - accuracy: 0.9000 - val_loss: 0.4761 - val_accuracy: 0.9400 - 77ms/epoch - 19ms/step\n",
            "Epoch 98/150\n",
            "4/4 - 0s - loss: 0.5188 - accuracy: 0.9000 - val_loss: 0.4716 - val_accuracy: 0.9400 - 70ms/epoch - 17ms/step\n",
            "Epoch 99/150\n",
            "4/4 - 0s - loss: 0.5146 - accuracy: 0.9000 - val_loss: 0.4668 - val_accuracy: 0.9400 - 62ms/epoch - 15ms/step\n",
            "Epoch 100/150\n",
            "4/4 - 0s - loss: 0.5100 - accuracy: 0.9000 - val_loss: 0.4622 - val_accuracy: 0.9000 - 118ms/epoch - 30ms/step\n",
            "Epoch 101/150\n",
            "4/4 - 0s - loss: 0.5056 - accuracy: 0.9000 - val_loss: 0.4576 - val_accuracy: 0.8200 - 65ms/epoch - 16ms/step\n",
            "Epoch 102/150\n",
            "4/4 - 0s - loss: 0.5010 - accuracy: 0.8900 - val_loss: 0.4531 - val_accuracy: 0.8200 - 51ms/epoch - 13ms/step\n",
            "Epoch 103/150\n",
            "4/4 - 0s - loss: 0.4969 - accuracy: 0.8900 - val_loss: 0.4492 - val_accuracy: 0.8000 - 82ms/epoch - 21ms/step\n",
            "Epoch 104/150\n",
            "4/4 - 0s - loss: 0.4933 - accuracy: 0.8900 - val_loss: 0.4453 - val_accuracy: 0.8000 - 89ms/epoch - 22ms/step\n",
            "Epoch 105/150\n",
            "4/4 - 0s - loss: 0.4897 - accuracy: 0.8700 - val_loss: 0.4416 - val_accuracy: 0.7800 - 67ms/epoch - 17ms/step\n",
            "Epoch 106/150\n",
            "4/4 - 0s - loss: 0.4863 - accuracy: 0.8300 - val_loss: 0.4380 - val_accuracy: 0.7800 - 53ms/epoch - 13ms/step\n",
            "Epoch 107/150\n",
            "4/4 - 0s - loss: 0.4828 - accuracy: 0.8200 - val_loss: 0.4345 - val_accuracy: 0.7800 - 67ms/epoch - 17ms/step\n",
            "Epoch 108/150\n",
            "4/4 - 0s - loss: 0.4790 - accuracy: 0.8700 - val_loss: 0.4310 - val_accuracy: 0.8000 - 76ms/epoch - 19ms/step\n",
            "Epoch 109/150\n",
            "4/4 - 0s - loss: 0.4754 - accuracy: 0.8900 - val_loss: 0.4277 - val_accuracy: 0.8200 - 122ms/epoch - 30ms/step\n",
            "Epoch 110/150\n",
            "4/4 - 0s - loss: 0.4720 - accuracy: 0.8900 - val_loss: 0.4245 - val_accuracy: 0.8400 - 104ms/epoch - 26ms/step\n",
            "Epoch 111/150\n",
            "4/4 - 0s - loss: 0.4687 - accuracy: 0.9000 - val_loss: 0.4214 - val_accuracy: 0.8800 - 62ms/epoch - 16ms/step\n",
            "Epoch 112/150\n",
            "4/4 - 0s - loss: 0.4653 - accuracy: 0.9000 - val_loss: 0.4182 - val_accuracy: 0.8800 - 38ms/epoch - 10ms/step\n",
            "Epoch 113/150\n",
            "4/4 - 0s - loss: 0.4621 - accuracy: 0.9000 - val_loss: 0.4151 - val_accuracy: 0.8800 - 52ms/epoch - 13ms/step\n",
            "Epoch 114/150\n",
            "4/4 - 0s - loss: 0.4585 - accuracy: 0.9000 - val_loss: 0.4122 - val_accuracy: 0.8800 - 53ms/epoch - 13ms/step\n",
            "Epoch 115/150\n",
            "4/4 - 0s - loss: 0.4553 - accuracy: 0.8900 - val_loss: 0.4095 - val_accuracy: 0.8200 - 58ms/epoch - 14ms/step\n",
            "Epoch 116/150\n",
            "4/4 - 0s - loss: 0.4523 - accuracy: 0.8900 - val_loss: 0.4069 - val_accuracy: 0.8200 - 36ms/epoch - 9ms/step\n",
            "Epoch 117/150\n",
            "4/4 - 0s - loss: 0.4494 - accuracy: 0.8900 - val_loss: 0.4039 - val_accuracy: 0.8400 - 37ms/epoch - 9ms/step\n",
            "Epoch 118/150\n",
            "4/4 - 0s - loss: 0.4462 - accuracy: 0.9000 - val_loss: 0.4008 - val_accuracy: 0.8800 - 35ms/epoch - 9ms/step\n",
            "Epoch 119/150\n",
            "4/4 - 0s - loss: 0.4426 - accuracy: 0.8900 - val_loss: 0.3978 - val_accuracy: 0.8600 - 37ms/epoch - 9ms/step\n",
            "Epoch 120/150\n",
            "4/4 - 0s - loss: 0.4397 - accuracy: 0.8900 - val_loss: 0.3945 - val_accuracy: 0.8800 - 53ms/epoch - 13ms/step\n",
            "Epoch 121/150\n",
            "4/4 - 0s - loss: 0.4365 - accuracy: 0.9000 - val_loss: 0.3913 - val_accuracy: 0.8800 - 56ms/epoch - 14ms/step\n",
            "Epoch 122/150\n",
            "4/4 - 0s - loss: 0.4335 - accuracy: 0.9000 - val_loss: 0.3879 - val_accuracy: 0.9000 - 37ms/epoch - 9ms/step\n",
            "Epoch 123/150\n",
            "4/4 - 0s - loss: 0.4300 - accuracy: 0.9000 - val_loss: 0.3851 - val_accuracy: 0.9400 - 52ms/epoch - 13ms/step\n",
            "Epoch 124/150\n",
            "4/4 - 0s - loss: 0.4274 - accuracy: 0.9100 - val_loss: 0.3826 - val_accuracy: 0.9400 - 34ms/epoch - 9ms/step\n",
            "Epoch 125/150\n",
            "4/4 - 0s - loss: 0.4247 - accuracy: 0.9300 - val_loss: 0.3803 - val_accuracy: 0.9600 - 52ms/epoch - 13ms/step\n",
            "Epoch 126/150\n",
            "4/4 - 0s - loss: 0.4232 - accuracy: 0.9300 - val_loss: 0.3788 - val_accuracy: 0.9600 - 63ms/epoch - 16ms/step\n",
            "Epoch 127/150\n",
            "4/4 - 0s - loss: 0.4217 - accuracy: 0.9400 - val_loss: 0.3772 - val_accuracy: 0.9600 - 53ms/epoch - 13ms/step\n",
            "Epoch 128/150\n",
            "4/4 - 0s - loss: 0.4193 - accuracy: 0.9500 - val_loss: 0.3743 - val_accuracy: 0.9600 - 54ms/epoch - 13ms/step\n",
            "Epoch 129/150\n",
            "4/4 - 0s - loss: 0.4159 - accuracy: 0.9400 - val_loss: 0.3703 - val_accuracy: 0.9600 - 58ms/epoch - 14ms/step\n",
            "Epoch 130/150\n",
            "4/4 - 0s - loss: 0.4116 - accuracy: 0.9400 - val_loss: 0.3667 - val_accuracy: 0.9600 - 52ms/epoch - 13ms/step\n",
            "Epoch 131/150\n",
            "4/4 - 0s - loss: 0.4079 - accuracy: 0.9300 - val_loss: 0.3631 - val_accuracy: 0.9600 - 53ms/epoch - 13ms/step\n",
            "Epoch 132/150\n",
            "4/4 - 0s - loss: 0.4044 - accuracy: 0.9300 - val_loss: 0.3604 - val_accuracy: 0.9600 - 37ms/epoch - 9ms/step\n",
            "Epoch 133/150\n",
            "4/4 - 0s - loss: 0.4012 - accuracy: 0.9300 - val_loss: 0.3581 - val_accuracy: 0.9600 - 37ms/epoch - 9ms/step\n",
            "Epoch 134/150\n",
            "4/4 - 0s - loss: 0.3991 - accuracy: 0.9300 - val_loss: 0.3562 - val_accuracy: 0.9600 - 36ms/epoch - 9ms/step\n",
            "Epoch 135/150\n",
            "4/4 - 0s - loss: 0.3967 - accuracy: 0.9400 - val_loss: 0.3539 - val_accuracy: 0.9600 - 38ms/epoch - 10ms/step\n",
            "Epoch 136/150\n",
            "4/4 - 0s - loss: 0.3934 - accuracy: 0.9400 - val_loss: 0.3508 - val_accuracy: 0.9600 - 42ms/epoch - 11ms/step\n",
            "Epoch 137/150\n",
            "4/4 - 0s - loss: 0.3903 - accuracy: 0.9300 - val_loss: 0.3484 - val_accuracy: 0.9600 - 37ms/epoch - 9ms/step\n",
            "Epoch 138/150\n",
            "4/4 - 0s - loss: 0.3876 - accuracy: 0.9400 - val_loss: 0.3464 - val_accuracy: 0.9600 - 52ms/epoch - 13ms/step\n",
            "Epoch 139/150\n",
            "4/4 - 0s - loss: 0.3854 - accuracy: 0.9300 - val_loss: 0.3450 - val_accuracy: 0.9400 - 54ms/epoch - 13ms/step\n",
            "Epoch 140/150\n",
            "4/4 - 0s - loss: 0.3830 - accuracy: 0.9300 - val_loss: 0.3432 - val_accuracy: 0.9400 - 53ms/epoch - 13ms/step\n",
            "Epoch 141/150\n",
            "4/4 - 0s - loss: 0.3810 - accuracy: 0.9100 - val_loss: 0.3406 - val_accuracy: 0.9400 - 35ms/epoch - 9ms/step\n",
            "Epoch 142/150\n",
            "4/4 - 0s - loss: 0.3782 - accuracy: 0.9100 - val_loss: 0.3370 - val_accuracy: 0.9400 - 37ms/epoch - 9ms/step\n",
            "Epoch 143/150\n",
            "4/4 - 0s - loss: 0.3741 - accuracy: 0.9300 - val_loss: 0.3331 - val_accuracy: 0.9600 - 49ms/epoch - 12ms/step\n",
            "Epoch 144/150\n",
            "4/4 - 0s - loss: 0.3713 - accuracy: 0.9300 - val_loss: 0.3305 - val_accuracy: 0.9600 - 35ms/epoch - 9ms/step\n",
            "Epoch 145/150\n",
            "4/4 - 0s - loss: 0.3680 - accuracy: 0.9300 - val_loss: 0.3281 - val_accuracy: 0.9600 - 52ms/epoch - 13ms/step\n",
            "Epoch 146/150\n",
            "4/4 - 0s - loss: 0.3657 - accuracy: 0.9400 - val_loss: 0.3255 - val_accuracy: 0.9600 - 49ms/epoch - 12ms/step\n",
            "Epoch 147/150\n",
            "4/4 - 0s - loss: 0.3634 - accuracy: 0.9400 - val_loss: 0.3228 - val_accuracy: 0.9600 - 55ms/epoch - 14ms/step\n",
            "Epoch 148/150\n",
            "4/4 - 0s - loss: 0.3605 - accuracy: 0.9300 - val_loss: 0.3202 - val_accuracy: 0.9600 - 51ms/epoch - 13ms/step\n",
            "Epoch 149/150\n",
            "4/4 - 0s - loss: 0.3574 - accuracy: 0.9300 - val_loss: 0.3180 - val_accuracy: 0.9600 - 55ms/epoch - 14ms/step\n",
            "Epoch 150/150\n",
            "4/4 - 0s - loss: 0.3549 - accuracy: 0.9300 - val_loss: 0.3157 - val_accuracy: 0.9600 - 53ms/epoch - 13ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Return probability\n",
        "model.predict(scaled_XTest)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHXFFEXKJptr",
        "outputId": "99218dfc-1674-48a0-977c-26b21fb03ad3"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 10ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.99301296e-02, 5.47838688e-01, 4.22231108e-01],\n",
              "       [9.29475963e-01, 6.66014031e-02, 3.92257329e-03],\n",
              "       [2.69314594e-04, 1.66923404e-01, 8.32807243e-01],\n",
              "       [2.67233383e-02, 5.46330512e-01, 4.26946223e-01],\n",
              "       [1.20816268e-02, 4.61735159e-01, 5.26183248e-01],\n",
              "       [9.11009014e-01, 8.30814391e-02, 5.90950018e-03],\n",
              "       [1.24863118e-01, 6.36257887e-01, 2.38878980e-01],\n",
              "       [1.94071280e-03, 3.03458393e-01, 6.94600761e-01],\n",
              "       [9.33780614e-03, 4.09164906e-01, 5.81497312e-01],\n",
              "       [7.85267949e-02, 6.25638247e-01, 2.95834929e-01],\n",
              "       [5.34987031e-03, 3.97189707e-01, 5.97460449e-01],\n",
              "       [9.25912917e-01, 6.82666600e-02, 5.82041591e-03],\n",
              "       [9.43494976e-01, 5.30122183e-02, 3.49282636e-03],\n",
              "       [9.27996039e-01, 6.66648149e-02, 5.33900317e-03],\n",
              "       [9.54239547e-01, 4.35108580e-02, 2.24960432e-03],\n",
              "       [2.48492826e-02, 5.58820367e-01, 4.16330338e-01],\n",
              "       [1.07165286e-03, 2.43669465e-01, 7.55258918e-01],\n",
              "       [8.13154727e-02, 6.16951168e-01, 3.01733404e-01],\n",
              "       [3.97798605e-02, 5.74641645e-01, 3.85578424e-01],\n",
              "       [1.25311094e-03, 2.50116855e-01, 7.48630106e-01],\n",
              "       [9.30583417e-01, 6.47616163e-02, 4.65500541e-03],\n",
              "       [9.88886505e-03, 4.48491633e-01, 5.41619480e-01],\n",
              "       [9.18585896e-01, 7.63097107e-02, 5.10446168e-03],\n",
              "       [1.47012039e-03, 2.61541456e-01, 7.36988425e-01],\n",
              "       [8.91143107e-04, 2.56352603e-01, 7.42756367e-01],\n",
              "       [1.63841504e-03, 2.83666939e-01, 7.14694560e-01],\n",
              "       [1.66782760e-03, 2.63989568e-01, 7.34342635e-01],\n",
              "       [7.92171399e-04, 2.29177445e-01, 7.70030379e-01],\n",
              "       [9.12361503e-01, 8.08717459e-02, 6.76683290e-03],\n",
              "       [9.19486225e-01, 7.46780634e-02, 5.83569286e-03],\n",
              "       [9.61762309e-01, 3.63252610e-02, 1.91236613e-03],\n",
              "       [9.63205040e-01, 3.53475139e-02, 1.44732359e-03],\n",
              "       [3.15069109e-02, 5.74611604e-01, 3.93881500e-01],\n",
              "       [9.41768765e-01, 5.47381490e-02, 3.49313370e-03],\n",
              "       [9.43096101e-01, 5.32121323e-02, 3.69170797e-03],\n",
              "       [3.35291610e-03, 3.23270380e-01, 6.73376739e-01],\n",
              "       [3.14734951e-02, 5.78705728e-01, 3.89820755e-01],\n",
              "       [9.42473292e-01, 5.40885851e-02, 3.43806157e-03],\n",
              "       [9.52687323e-01, 4.47762199e-02, 2.53647449e-03],\n",
              "       [9.67258334e-01, 3.14303301e-02, 1.31124456e-03],\n",
              "       [4.80721984e-03, 3.60245019e-01, 6.34947717e-01],\n",
              "       [4.19264175e-02, 6.05545998e-01, 3.52527589e-01],\n",
              "       [1.82164460e-02, 5.19805074e-01, 4.61978465e-01],\n",
              "       [9.54834700e-01, 4.29884419e-02, 2.17678212e-03],\n",
              "       [9.48978186e-01, 4.82384935e-02, 2.78328569e-03],\n",
              "       [1.10932164e-01, 6.25375152e-01, 2.63692677e-01],\n",
              "       [9.06992424e-03, 4.26594406e-01, 5.64335644e-01],\n",
              "       [4.25006868e-03, 3.63706410e-01, 6.32043540e-01],\n",
              "       [2.93696318e-02, 5.64333081e-01, 4.06297326e-01],\n",
              "       [5.46449330e-04, 2.17658535e-01, 7.81795025e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Return the classes\n",
        "pred = np.argmax(model.predict(scaled_XTest),axis = 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QW2z4F1wKRHo",
        "outputId": "8e676e4c-5ad8-47dd-ab1c-d36a1abf5db4"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 5ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "prediction_dict = {0: \"setosa\", 1: \"versicolor\", 2: \"virginica\"}\n",
        "pred2 = pd.Series(pred)\n",
        "pred2 = pred2.map(prediction_dict)"
      ],
      "metadata": {
        "id": "SzEeCJnpKTt3"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred2 = pd.DataFrame(pred2)\n",
        "print(pred2.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vv9IGJ-3KLHj",
        "outputId": "42d5e7a4-d3dc-4ac7-dfd3-d74b09ed109c"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            0\n",
            "0  versicolor\n",
            "1      setosa\n",
            "2   virginica\n",
            "3  versicolor\n",
            "4   virginica\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "YTest = np.argmax(YTest,axis = 1)"
      ],
      "metadata": {
        "id": "DlbMwVRWVO6p"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score"
      ],
      "metadata": {
        "id": "oQtxTD8uWDbQ"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(confusion_matrix(pred,YTest))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LFnbIYrPWJUs",
        "outputId": "1c4560b2-9015-487c-90a8-746a247e0621"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[19  0  0]\n",
            " [ 0 13  0]\n",
            " [ 0  2 16]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(pred,YTest))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14EDohejWNz6",
        "outputId": "4afbee30-6a80-4008-ee2b-5262e14c9c21"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        19\n",
            "           1       0.87      1.00      0.93        13\n",
            "           2       1.00      0.89      0.94        18\n",
            "\n",
            "    accuracy                           0.96        50\n",
            "   macro avg       0.96      0.96      0.96        50\n",
            "weighted avg       0.97      0.96      0.96        50\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(accuracy_score(pred,YTest))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFdxjVMAWW62",
        "outputId": "f296ea22-7c47-4cd6-90f2-5b260cfd38d3"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('iris_classification_model')"
      ],
      "metadata": {
        "id": "GvRT_18gWhxE"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model"
      ],
      "metadata": {
        "id": "mmTKk9hzWnPp"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_model = load_model('iris_classification_model')"
      ],
      "metadata": {
        "id": "64kE0_G8Wrfo"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.utils.plot_model(new_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "Wg2TS3uEWu43",
        "outputId": "b36c42ac-0390-4d8c-a64e-a9b419739ba4"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_model.predict(scaled_XTest)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BFr4LPlW6bR",
        "outputId": "d260790d-88a3-466b-a219-6a67914ab23d"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 8ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.99301296e-02, 5.47838688e-01, 4.22231108e-01],\n",
              "       [9.29475963e-01, 6.66014031e-02, 3.92257329e-03],\n",
              "       [2.69314594e-04, 1.66923404e-01, 8.32807243e-01],\n",
              "       [2.67233383e-02, 5.46330512e-01, 4.26946223e-01],\n",
              "       [1.20816268e-02, 4.61735159e-01, 5.26183248e-01],\n",
              "       [9.11009014e-01, 8.30814391e-02, 5.90950018e-03],\n",
              "       [1.24863118e-01, 6.36257887e-01, 2.38878980e-01],\n",
              "       [1.94071280e-03, 3.03458393e-01, 6.94600761e-01],\n",
              "       [9.33780614e-03, 4.09164906e-01, 5.81497312e-01],\n",
              "       [7.85267949e-02, 6.25638247e-01, 2.95834929e-01],\n",
              "       [5.34987031e-03, 3.97189707e-01, 5.97460449e-01],\n",
              "       [9.25912917e-01, 6.82666600e-02, 5.82041591e-03],\n",
              "       [9.43494976e-01, 5.30122183e-02, 3.49282636e-03],\n",
              "       [9.27996039e-01, 6.66648149e-02, 5.33900317e-03],\n",
              "       [9.54239547e-01, 4.35108580e-02, 2.24960432e-03],\n",
              "       [2.48492826e-02, 5.58820367e-01, 4.16330338e-01],\n",
              "       [1.07165286e-03, 2.43669465e-01, 7.55258918e-01],\n",
              "       [8.13154727e-02, 6.16951168e-01, 3.01733404e-01],\n",
              "       [3.97798605e-02, 5.74641645e-01, 3.85578424e-01],\n",
              "       [1.25311094e-03, 2.50116855e-01, 7.48630106e-01],\n",
              "       [9.30583417e-01, 6.47616163e-02, 4.65500541e-03],\n",
              "       [9.88886505e-03, 4.48491633e-01, 5.41619480e-01],\n",
              "       [9.18585896e-01, 7.63097107e-02, 5.10446168e-03],\n",
              "       [1.47012039e-03, 2.61541456e-01, 7.36988425e-01],\n",
              "       [8.91143107e-04, 2.56352603e-01, 7.42756367e-01],\n",
              "       [1.63841504e-03, 2.83666939e-01, 7.14694560e-01],\n",
              "       [1.66782760e-03, 2.63989568e-01, 7.34342635e-01],\n",
              "       [7.92171399e-04, 2.29177445e-01, 7.70030379e-01],\n",
              "       [9.12361503e-01, 8.08717459e-02, 6.76683290e-03],\n",
              "       [9.19486225e-01, 7.46780634e-02, 5.83569286e-03],\n",
              "       [9.61762309e-01, 3.63252610e-02, 1.91236613e-03],\n",
              "       [9.63205040e-01, 3.53475139e-02, 1.44732359e-03],\n",
              "       [3.15069109e-02, 5.74611604e-01, 3.93881500e-01],\n",
              "       [9.41768765e-01, 5.47381490e-02, 3.49313370e-03],\n",
              "       [9.43096101e-01, 5.32121323e-02, 3.69170797e-03],\n",
              "       [3.35291610e-03, 3.23270380e-01, 6.73376739e-01],\n",
              "       [3.14734951e-02, 5.78705728e-01, 3.89820755e-01],\n",
              "       [9.42473292e-01, 5.40885851e-02, 3.43806157e-03],\n",
              "       [9.52687323e-01, 4.47762199e-02, 2.53647449e-03],\n",
              "       [9.67258334e-01, 3.14303301e-02, 1.31124456e-03],\n",
              "       [4.80721984e-03, 3.60245019e-01, 6.34947717e-01],\n",
              "       [4.19264175e-02, 6.05545998e-01, 3.52527589e-01],\n",
              "       [1.82164460e-02, 5.19805074e-01, 4.61978465e-01],\n",
              "       [9.54834700e-01, 4.29884419e-02, 2.17678212e-03],\n",
              "       [9.48978186e-01, 4.82384935e-02, 2.78328569e-03],\n",
              "       [1.10932164e-01, 6.25375152e-01, 2.63692677e-01],\n",
              "       [9.06992424e-03, 4.26594406e-01, 5.64335644e-01],\n",
              "       [4.25006868e-03, 3.63706410e-01, 6.32043540e-01],\n",
              "       [2.93696318e-02, 5.64333081e-01, 4.06297326e-01],\n",
              "       [5.46449330e-04, 2.17658535e-01, 7.81795025e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "9GNcjPOJW8db"
      }
    }
  ]
}