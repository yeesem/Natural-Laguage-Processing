{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNbO3Z/JD9PlBko+mb5rJA9"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kr9C013VJ8tx",
        "outputId": "ed463bcb-f2ef-45f3-9322-48fea3161431"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "count of n-gram ('i', 'am', 'happy') : 2\n",
            "n-gram ('i', 'am', 'learning') missing\n",
            "n-gram ('i', 'am', 'learning') found\n"
          ]
        }
      ],
      "source": [
        "# Manipulate n_gram count dictionary\n",
        "\n",
        "n_gram_counts = {\n",
        "    ('i','am','happy') : 2,\n",
        "    ('am','happy','because') : 1\n",
        "}\n",
        "\n",
        "# Get count for an n-gram tuple\n",
        "print(f\"count of n-gram {('i', 'am', 'happy')} : {n_gram_counts[('i', 'am', 'happy')]}\")\n",
        "\n",
        "# Check if n-gram is present in the dictionary\n",
        "if ('i','am','learning') in n_gram_counts:\n",
        "  print(f\"n-gram {('i', 'am', 'learning')} found\")\n",
        "else:\n",
        "  print(f\"n-gram {('i', 'am', 'learning')} missing\")\n",
        "\n",
        "# Update the count in the word count dictionary\n",
        "n_gram_counts[('i', 'am', 'learning')] = 1\n",
        "if ('i', 'am', 'learning') in n_gram_counts:\n",
        "    print(f\"n-gram {('i', 'am', 'learning')} found\")\n",
        "else:\n",
        "    print(f\"n-gram {('i', 'am', 'learning')} missing\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenate tuple for prefix and tuple with the last word to create the n_gram\n",
        "prefix = ('i', 'am', 'happy')\n",
        "word = 'because'\n",
        "\n",
        "# Note here the syntax for creating a tuple for a single word\n",
        "n_gram = prefix + (word,)\n",
        "print(n_gram)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jDAfKyp4LQZR",
        "outputId": "0a46d850-2d0a-4d2e-b01d-cc5b7e2f83eb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('i', 'am', 'happy', 'because')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "\n",
        "def single_pass_trigram_count_matrix(corpus):\n",
        "\n",
        "  bigrams = []\n",
        "  vocabulary = []\n",
        "  count_matrix_dict = defaultdict(dict)\n",
        "\n",
        "  # Go through the corpus once with a sliding window\n",
        "  for i in range(len(corpus) - 3 + 1):\n",
        "    # Sliding window starts at position i and contains 3 words\n",
        "    trigram = tuple(corpus[i : i+3])\n",
        "\n",
        "    # \"if not bigram in bigrams\" is same as \"if bigram not in bigrams\"\n",
        "    bigram = trigram[0 : -1]\n",
        "    if not bigram in bigrams:\n",
        "      bigrams.append(bigram)\n",
        "\n",
        "    last_word = trigram[-1]\n",
        "    if not last_word in vocabulary:\n",
        "      vocabulary.append(last_word)\n",
        "\n",
        "    if (bigram,last_word) not in count_matrix_dict:\n",
        "      count_matrix_dict[bigram,last_word] = 0\n",
        "\n",
        "    count_matrix_dict[bigram,last_word] += 1\n",
        "\n",
        "  # Convert the count_matrix to np.array to fill in the blanks\n",
        "  count_matrix = np.zeros((len(bigrams),len(vocabulary)))\n",
        "\n",
        "  for trigram_key, trigram_count in count_matrix_dict.items():\n",
        "    count_matrix[bigrams.index(trigram_key[0]),\n",
        "                 vocabulary.index(trigram_key[1])] = trigram_count\n",
        "\n",
        "  # np.array to pandas dataframe conversion\n",
        "  count_matrix = pd.DataFrame(count_matrix,index=bigrams,columns = vocabulary)\n",
        "\n",
        "  return bigrams,vocabulary,count_matrix\n",
        "\n",
        "corpus = ['i', 'am', 'happy', 'because', 'i', 'am', 'learning', '.']\n",
        "\n",
        "bigrams,vocabulary,count_matrix = single_pass_trigram_count_matrix(corpus)\n",
        "\n",
        "print(count_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KyJ985jLLke1",
        "outputId": "0db016e8-b005-48fb-a83e-747f7d69d5fd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                  happy  because    i   am  learning    .\n",
            "(i, am)             1.0      0.0  0.0  0.0       1.0  0.0\n",
            "(am, happy)         0.0      1.0  0.0  0.0       0.0  0.0\n",
            "(happy, because)    0.0      0.0  1.0  0.0       0.0  0.0\n",
            "(because, i)        0.0      0.0  0.0  1.0       0.0  0.0\n",
            "(am, learning)      0.0      0.0  0.0  0.0       0.0  1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Probability Matrix"
      ],
      "metadata": {
        "id": "ghnYAj56wcq6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Probability matrix\n",
        "# Create probability matrix from the count matrix\n",
        "row_sums = count_matrix.sum(axis = 1)\n",
        "\n",
        "# Divide each row by its sum\n",
        "prob_matrix = count_matrix.div(row_sums,axis = 0)\n",
        "\n",
        "print(prob_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHqj1P7gwXy6",
        "outputId": "986568be-6ec8-470f-a69d-69496f4de9bb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                  happy  because    i   am  learning    .\n",
            "(i, am)             0.5      0.0  0.0  0.0       0.5  0.0\n",
            "(am, happy)         0.0      1.0  0.0  0.0       0.0  0.0\n",
            "(happy, because)    0.0      0.0  1.0  0.0       0.0  0.0\n",
            "(because, i)        0.0      0.0  0.0  1.0       0.0  0.0\n",
            "(am, learning)      0.0      0.0  0.0  0.0       0.0  1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the probablity of a trigram in the probability matrix\n",
        "trigram = ('i', 'am', 'happy')\n",
        "\n",
        "# Find the prefix bigram\n",
        "bigram = trigram[0 : -1]\n",
        "print(\"bigram : \", bigram)\n",
        "\n",
        "# Find the last word of the trigram\n",
        "word = trigram[-1]\n",
        "print(\"Word : \",word)\n",
        "\n",
        "trigram_prob = prob_matrix[word][bigram]\n",
        "print(f\"Trigram probability : {trigram_prob}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JzZ7TnGyxp8K",
        "outputId": "51b6fd64-718d-4a1f-f1d1-88a0fa21a2d0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bigram :  ('i', 'am')\n",
            "Word :  happy\n",
            "Trigram probability : 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# lists all words in vocabulary starting with a given prefix\n",
        "vocabulary = ['i', 'am', 'happy', 'because', 'learning', '.', 'have', 'you', 'seen','it', '?']\n",
        "starts_with = 'ha'\n",
        "\n",
        "print(f\"Words in vocabulary starting with prefix : {starts_with}\\n\")\n",
        "for word in vocabulary:\n",
        "  if word.startswith(starts_with):\n",
        "    print(word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DmRXZI5HykXV",
        "outputId": "1f3acebb-f73a-4abd-f020-c45c7d36ff6c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Words in vocabulary starting with prefix : ha\n",
            "\n",
            "happy\n",
            "have\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Language Model Evaluation"
      ],
      "metadata": {
        "id": "DqSJP1suy3rN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train/Validation/Test Split\n",
        "import random\n",
        "def train_validation_test_split(data,train_percent,validation_percent):\n",
        "\n",
        "  # Fixed seed here for reproducibility\n",
        "  random.seed(87)\n",
        "\n",
        "  # Reshuffle all input sentences\n",
        "  random.shuffle(data)\n",
        "\n",
        "  # Need to /100 because train_percent is between 0 - 100\n",
        "  train_size = int(len(data) * train_percent / 100)\n",
        "  train_data = data[0: train_size]\n",
        "\n",
        "  validation_size = int(len(data) * validation_percent / 100)\n",
        "  validation_data = data[train_size : train_size + validation_size]\n",
        "\n",
        "  test_data = data[train_size + validation_size : ]\n",
        "\n",
        "  return train_data,validation_data,test_data\n",
        "\n",
        "data = [x for x in range (0, 100)]\n",
        "\n",
        "train_data, validation_data, test_data = train_validation_test_split(data, 80, 10)\n",
        "print(\"split 80/10/10:\\n\",f\"train data:{train_data}\\n\", f\"validation data:{validation_data}\\n\",\n",
        "      f\"test data:{test_data}\\n\")\n",
        "\n",
        "train_data, validation_data, test_data = train_validation_test_split(data, 98, 1)\n",
        "print(\"split 98/1/1:\\n\",f\"train data:{train_data}\\n\", f\"validation data:{validation_data}\\n\",\n",
        "      f\"test data:{test_data}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "INI95RCzy7Mo",
        "outputId": "26c1cbc6-6a9e-4752-fd55-52b86befed44"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "split 80/10/10:\n",
            " train data:[28, 76, 5, 0, 62, 29, 54, 95, 88, 58, 4, 22, 92, 14, 50, 77, 47, 33, 75, 68, 56, 74, 43, 80, 83, 84, 73, 93, 66, 87, 9, 91, 64, 79, 20, 51, 17, 27, 12, 31, 67, 81, 7, 34, 45, 72, 38, 30, 16, 60, 40, 86, 48, 21, 70, 59, 6, 19, 2, 99, 37, 36, 52, 61, 97, 44, 26, 57, 89, 55, 53, 85, 3, 39, 10, 71, 23, 32, 25, 8]\n",
            " validation data:[78, 65, 63, 11, 49, 98, 1, 46, 15, 41]\n",
            " test data:[90, 96, 82, 42, 35, 13, 69, 24, 94, 18]\n",
            "\n",
            "split 98/1/1:\n",
            " train data:[66, 23, 29, 28, 52, 87, 70, 13, 15, 2, 62, 43, 82, 50, 40, 32, 30, 79, 71, 89, 6, 10, 34, 78, 11, 49, 39, 42, 26, 46, 58, 96, 97, 8, 56, 86, 33, 93, 92, 91, 57, 65, 95, 20, 72, 3, 12, 9, 47, 37, 67, 1, 16, 74, 53, 99, 54, 68, 5, 18, 27, 17, 48, 36, 24, 45, 73, 19, 41, 59, 21, 98, 0, 31, 4, 85, 80, 64, 84, 88, 25, 44, 61, 22, 60, 94, 76, 38, 77, 81, 90, 69, 63, 7, 51, 14, 55, 83]\n",
            " validation data:[35]\n",
            " test data:[75]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Perplexity"
      ],
      "metadata": {
        "id": "ZgZGG7UA1BRs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perplexity formula:\n",
        "\n",
        "\\begin{equation*}\n",
        "PP(W)=\\sqrt[M]{\\prod_{i=1}^{m}{\\frac{1}{P(w_i|w_{i-1})}}}\n",
        "\\end{equation*}\n",
        "\n",
        "Remember from calculus:\n",
        "\n",
        "\\begin{equation*}\n",
        "\\sqrt[M]{\\frac{1}{x}} = x^{-\\frac{1}{M}}\n",
        "\\end{equation*}"
      ],
      "metadata": {
        "id": "TBNUfamf1WYo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "p = 10 ** (-250)\n",
        "M = 100\n",
        "perplexity = p ** (-1/M)\n",
        "print(perplexity)"
      ],
      "metadata": {
        "id": "kYvFTGPC1DCL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}